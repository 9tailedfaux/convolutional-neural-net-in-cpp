
§
Ωvoid wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)`Ä*2Ä8í∏`@í∏`Hí∏`Xb=gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropFilterhu≥™&B
Æ
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_256x64_16x4_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_256x64_16x4_nhwc_unity_stride_align4::Params)ˇ ÄÄ*Ä2à8â/@â/Hâ/Xb<gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInputh
å
 void fft2d_c2r_32x32<float, false, true, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)@ ¿ò*Ä2Ä8Ñ¯@Å∞HÅÿbsequential/conv2d_1/ReluhuZUÖB
¢
Ωvoid wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)TÄ*2Ä8Ñà@ÑàHÑàXb;gradient_tape/sequential/conv2d/Conv2D/Conv2DBackpropFilterhu≥™&B
W
ampere_gcgemm_64x64_ntzÄ¿*Ä2†8Ñ†@ÅÄHÅêbsequential/conv2d_1/ReluhuMUB
§
Ωvoid wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)`Ä*2Ä8Ñ»@Ñ»HÑ»Xb=gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropFilterhu≥™&B
Ó
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Ñ∞@Ñ∞HÑ∞b(gradient_tape/sequential/conv2d/ReluGradhuZUÖB
·
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)@ ¿ò*Ä2Ä8ÑÄ@Å∏HÅ»bsequential/conv2d_1/ReluhuZUÖB

°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Ñò@ÑòHÑòb*gradient_tape/sequential/conv2d_1/ReluGradhuZUÖB
â
Hcudnn_infer_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1~ÄÄ*Ä2Ä8É∞@É∞HÉ∞bsequential/conv2d_3/ReluhuMUB
ËS
ÖSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)| ÄÄ*Ä28Çà@ÇàHÇàXb=gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropFilterh
ò
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Äƒ*Ä2Ä 8Ç»@Ç»HÇ»b:gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGradhuZUÖB
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2qÄ8É@ÉHÉXb<gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInputhu  »B
ë

≤	void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::MaxReducer<float, 0>, long>(Eigen::internal::MaxReducer<float, 0>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)0*Ä28Ç†@Ç†HÇ†b:categorical_crossentropy/softmax_cross_entropy_with_logitshu¶™¶B
r
4cudnn_infer_ampere_scudnn_128x32_relu_interior_nn_v1ÄÄ**@2ê8Ç–@Ç–HÇ–bsequential/conv2d/ReluhuMUB
v
4cudnn_infer_ampere_scudnn_128x64_relu_interior_nn_v1ÄÄÄ*Ä2§8Ç∏@Ç∏HÇ∏bsequential/conv2d_2/ReluhuMUB
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2bÄ8Ç†@Ç†HÇ†Xb<gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInputhu  »B
Æ
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params)° Ä¿*Ä2§8Ç†	@Ç†	HÇ†	Xb<gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropInputh
Æ
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params)° Ä¿*Ä2ê8Ç¯@Ç¯HÇ¯Xb<gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInputh
Ì
§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä*‡2Ä8Ç»@Ç»HÇ»b sequential/max_pooling2d/MaxPoolhu  ØB

°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Ç¯@Ç¯HÇ¯b*gradient_tape/sequential/conv2d_2/ReluGradhuZUÖB
Ê
ãvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float) 0*Ä2Ä 8Å®@Å®HÅ®b3gradient_tape/sequential/conv2d/BiasAdd/BiasAddGradhu  »B

°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Å†@Å†HÅ†b*gradient_tape/sequential/conv2d_3/ReluGradhuZUÖB
Ç

£	void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, long>(Eigen::internal::SumReducer<float>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)(*Ä28Å»@Å»HÅ»b:categorical_crossentropy/softmax_cross_entropy_with_logitshu  »B
Ë
ãvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float) 0*Ä2Ä 8Å¿@Å¿HÅ¿b5gradient_tape/sequential/conv2d_1/BiasAdd/BiasAddGradhu  »B
∂
◊void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, long>(Eigen::internal::SumReducer<float>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)(*Ä28Å†@Å†HÅ†b:categorical_crossentropy/softmax_cross_entropy_with_logitshu  »B
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Åê@ÅêHÅêXb<gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInputhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Åà@ÅàHÅàXb<gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropInputhu  »B
Ç
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8ÅÄ@ÅÄHÅÄXb=gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropFilterhu  »B
ô
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä$*Ä2Ä@8Åÿ@ÅÿHÅÿb<gradient_tape/sequential/max_pooling2d_1/MaxPool/MaxPoolGradhu  »B
Ç
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Å®@Å®HÅ®Xb=gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropFilterhu  »B
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Å†@Å†HÅ†Xb<gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropInputhu  »B
ä
Hcudnn_infer_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile244t_nt_v1ÇÄÄ*Ä2Ä8Å@ÅHÅbsequential/conv2d_5/ReluhugUÖA
´
»void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4::Params)v ÄÄ*Ä2»8Äê@ÄêHÄêXb<gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropInputh
Ô
§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä*ê2Ä8Å¯@Å¯HÅ¯b"sequential/max_pooling2d_1/MaxPoolhu ¿®B
W
ampere_sgemm_128x128_nnvÄÇ*Ä2	$8Å@ÅHÅbsequential/conv2d_4/ReluhuMUB
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Ä@ÄHÄXb<gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInputhu  »B
˜S
ìSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 3, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 3, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)¶ Ä¿*Ä28Å‡@Å‡HÅ‡Xb=gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropFilterh
ö
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä*Ä2ÄÄ8Å–@Å–HÅ–b<gradient_tape/sequential/max_pooling2d_2/MaxPool/MaxPoolGradhu  »B
˛
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*Ä2Ä8Ä»@Ä»HÄ»b5gradient_tape/sequential/conv2d_2/BiasAdd/BiasAddGradhu  »B
ËS
ÖSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)| ÄÄ*Ä28Ä¿@Ä¿HÄ¿Xb=gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropFilterh
´
»void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4::Params)v ÄÄ*Ä2†8Å∏@Å∏HÅ∏Xb<gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropInputh
˛
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*Ä2Ä8Ä®@Ä®HÄ®b5gradient_tape/sequential/conv2d_3/BiasAdd/BiasAddGradhu  »B
¥
™void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä`*Ä2Ä8Ä¯@Ä¯HÄ¯bagradient_tape/sequential/conv2d/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizerhuZUÖB
ˇ
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2T8Åÿ@ÅÿHÅÿb%Adam/Adam/update_12/ResourceApplyAdamhuZUÖB
ƒ
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)@ÄÇ*Ä2@8Äÿ@ÄÿHÄÿbsequential/conv2d_4/ReluhuZUÖB
ø
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)@Ä±*Ä2@8Ä–@Ä–HÄ–bsequential/conv2d_4/ReluhuZUÖB
Ç
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Åê@ÅêHÅêXb=gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropFilterhu  »B
Ç
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äà@ÄàHÄàXb=gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropFilterhu  »B

°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8ÄÄ@ÄÄHÄÄb*gradient_tape/sequential/conv2d_5/ReluGradhuZUÖB
¡
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4::Params)d ÄÄ*Ä28ÄÄ@ÄÄHÄÄXbsequential/dense/MatMulh
Ì
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Äx@ÄxHÄxb*gradient_tape/sequential/conv2d_4/ReluGradhuZUÖB
‹
ûvoid fft2d_r2c_32x32<float, false, 5u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)@ ¿ò*Ä2@8Äx@ÄxHÄxbsequential/conv2d_1/ReluhuZUÖB
ˇ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äp@ÄpHÄpXb=gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropFilterhu  »B
∂
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)Ä*Ä2Ä8Äp@ÄpHÄpb5gradient_tape/sequential/conv2d_5/BiasAdd/BiasAddGradhuZUÖB
ˇ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äh@ÄhHÄhXb=gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropFilterhu  »B
˛
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Äh@ÄhHÄhXb<gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropInputhu  »B
˛
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä`@Ä`HÄ`Xb<gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropInputhu  »B
≥
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long) *Ä28ÅX@ÅXHÅXbArgMaxhuZUÖB
µ
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long) *Ä28ÄP@ÄPHÄPbArgMax_1huZUÖB
œ
Üvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4>(cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4::Params)î Ä¿*Ä2@8ÄH@ÄHHÄHb'gradient_tape/sequential/dense/MatMul_1h
Œ
Üvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x10_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x10_tn_align4::Params)X ÄÄ*Ä28ÄH@ÄHHÄHXb%gradient_tape/sequential/dense/MatMulh
∂
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)Ä*Ä2Ä8Ä@@Ä@HÄ@b5gradient_tape/sequential/conv2d_4/BiasAdd/BiasAddGradhuZUÖB
∞
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä!*Ä2Ä8Ä@@Ä@HÄ@bbgradient_tape/sequential/max_pooling2d_2/MaxPool/MaxPoolGrad-2-TransposeNHWCToNCHW-LayoutOptimizerhu  »B
˛
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Å8@Å8HÅ8Xb<gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropInputhu  »B
Î
§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä * 2Ä8Ä8@Ä8HÄ8b"sequential/max_pooling2d_2/MaxPoolhu  »B
”
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align4::Params)Z ÄÄ*Ä28Ä8@Ä8HÄ8Xb'gradient_tape/sequential/dense_1/MatMulhugUÖA
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2H8Ä8@Ä8HÄ8b%Adam/Adam/update_10/ResourceApplyAdamhuZUÖB
˛
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä0@Ä0HÄ0Xb<gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropInputhu  »B
≈
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params)^ ÄÄ*Ä28Ä0@Ä0HÄ0Xbsequential/dense_1/MatMulhugUÖA
”
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nt_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_nt_align4::Params)\ ÄÄ*Ä28Ä0@Ä0HÄ0b)gradient_tape/sequential/dense_1/MatMul_1hugUÖA
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä0@Ä0HÄ0b$Adam/Adam/update_4/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2$8Ä0@Ä0HÄ0b$Adam/Adam/update_6/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2$8Ä0@Ä0HÄ0b$Adam/Adam/update_8/ResourceApplyAdamhuZUÖB
≈
Èvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_quotient_op<float, float>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_quotient_op<float, float>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long).*Ä28Ä(@Ä(HÄ(b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
≠
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long)(*Ä28Ä(@Ä(HÄ(b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
ˇ
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Ä(@Ä(HÄ(Xb=gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropFilterhu  »B
√
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 28Ä(@Ä(HÄ(Xb=gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropFilterhu  »B
˘
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä(@Ä(HÄ(b"Adam/Adam/update/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä(@Ä(HÄ(b$Adam/Adam/update_2/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä228Ä(@Ä(HÄ(b%Adam/Adam/update_14/ResourceApplyAdamhuZUÖB
ò
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä!*Ä2Ä8Ä(@Ä(HÄ(bJsequential/max_pooling2d_2/MaxPool-0-2-TransposeNCHWToNHWC-LayoutOptimizerhu  »B
ˇ
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Å @Å HÅ b5gradient_tape/sequential/conv2d_2/BiasAdd/BiasAddGradhuZUÖB
ˇ	
£	void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)&*Ä28Ä @Ä HÄ b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
ø
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)(ÄH* 28Ä @Ä HÄ bsequential/conv2d_4/Reluhu  »B
√
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 2 8Ä @Ä HÄ Xb=gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropFilterhu  »B
Õ
ëvoid tensorflow::(anonymous namespace)::GenerateNormalizedProb<float, float, 4>(float const*, float const*, float const*, float*, int, int, bool) *Ä228Ä @Ä HÄ bsequential/dense_1/Softmaxhu  »B
ç
Tvoid tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int)*Ä2 8Ä @Ä HÄ bsequential/dense/BiasAddhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b%Adam/Adam/update_13/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_3/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_5/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_7/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_9/ResourceApplyAdamhuZUÖB
˝
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä @Ä HÄ b3gradient_tape/sequential/conv2d/BiasAdd/BiasAddGradhuZUÖB
Ω
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ bsequential/conv2d/ReluhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ bsequential/conv2d_2/ReluhuZUÖB
Ê
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb=gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropFilterhuZUÖB
Â
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb<gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ bsequential/conv2d_1/ReluhuZUÖB
Ê
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb=gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropFilterhuZUÖB
Â
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb<gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ bsequential/conv2d_3/ReluhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ bsequential/conv2d_4/ReluhuZUÖB
Â
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb<gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropInputhuZUÖB
Â
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb<gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropInputhuZUÖB
ø
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ bsequential/conv2d_5/ReluhuZUÖB
Ê
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ Xb=gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropFilterhuZUÖB
Â
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ Xb<gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropInputhuZUÖB
√
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 28Å@ÅHÅXb=gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropFilterhu  »B
€
ùvoid splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*) *Ä2»8Å@ÅHÅXbsequential/dense_1/MatMulhu  »B
Ê
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Å@ÅHÅXb=gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropFilterhuZUÖB
K
"AddV2_GPU_DT_INT64_DT_INT64_kernel*Ä28Ä@ÄHÄbAdam/addhuZUÖB
H
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä@ÄHÄbCast_3hu  »B
M
!Cast_GPU_DT_INT64_DT_FLOAT_kernel*Ä28Ä@ÄHÄbAdam/Cast_1hu  »B
_
!Cast_GPU_DT_INT64_DT_FLOAT_kernel*Ä2d8Ä@ÄHÄbcategorical_crossentropy/Casthu  »B
G
!Equal_GPU_DT_INT64_DT_BOOL_kernel*Ä28Ä@ÄHÄbEqualhuZUÖB
P
%LogicalAnd_GPU_DT_BOOL_DT_BOOL_kernel*Ä28Ä@ÄHÄb
LogicalAndhuZUÖB
I
 Pow_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbAdam/PowhuZUÖB
K
 Pow_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄb
Adam/Pow_1huZUÖB
Å
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbdiv_no_nan_1huZUÖB
÷
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2 8Ä@ÄHÄbsequential/dense/ReluhuZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_1huZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_2huZUÖB
ö
avoid cask_cudnn_infer::computeOffsetsKernel<false, false>(cask_cudnn_infer::ComputeOffsetsParams)*Ä28Ä@ÄHÄbsequential/conv2d_2/Reluhu  »B
ò
avoid cask_cudnn_infer::computeOffsetsKernel<false, false>(cask_cudnn_infer::ComputeOffsetsParams)*Ä28Ä@ÄHÄbsequential/conv2d/Reluhu  »B
˝
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2 8Ä@ÄHÄXb<gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInputhu  »B
˝
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb<gradient_tape/sequential/conv2d_2/Conv2D/Conv2DBackpropInputhu  »B
˝
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb<gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropInputhu  »B
˝
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb<gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropInputhu  »B
˛
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä@ÄHÄXb<gradient_tape/sequential/conv2d_5/Conv2D/Conv2DBackpropInputhu  »B
˛
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä@ÄHÄXb=gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropFilterhu  »B
˛
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä@ÄHÄXb=gradient_tape/sequential/conv2d_4/Conv2D/Conv2DBackpropFilterhu  »B
π
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)(ÄD* 28Ä@ÄHÄbsequential/conv2d_3/ReluhuZU∑B
π
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)(ÄD* 28Ä@ÄHÄbsequential/conv2d_5/ReluhuZU∑B
Ÿ
ùvoid splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*) *Ä2Ä8Ä@ÄHÄXbsequential/dense/MatMulhu  »B
™
Rvoid tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int) †*Ä28Ä@ÄHÄb4gradient_tape/sequential/dense_1/BiasAdd/BiasAddGradhuZUÖB
®
Rvoid tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int) Ä*Ä2 8Ä@ÄHÄb2gradient_tape/sequential/dense/BiasAdd/BiasAddGradhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä@ÄHÄb$Adam/Adam/update_1/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä@ÄHÄb%Adam/Adam/update_11/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä@ÄHÄb%Adam/Adam/update_15/ResourceApplyAdamhuZUÖB
Í
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb3gradient_tape/sequential/conv2d/BiasAdd/BiasAddGradhuZUÖB
Ï
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb5gradient_tape/sequential/conv2d_1/BiasAdd/BiasAddGradhuZUÖB
Ï
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb5gradient_tape/sequential/conv2d_2/BiasAdd/BiasAddGradhuZUÖB
Ï
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb5gradient_tape/sequential/conv2d_3/BiasAdd/BiasAddGradhuZUÖB
ˇ
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb5gradient_tape/sequential/conv2d_1/BiasAdd/BiasAddGradhuZUÖB
ˇ
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb5gradient_tape/sequential/conv2d_3/BiasAdd/BiasAddGradhuZUÖB
Å
≈void tensorflow::functor::RowReduceKernel<cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, cub::Sum>(cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, int, int, cub::Sum, std::iterator_traits<cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long> >::value_type)*Ä2 8Ä@ÄHÄbsequential/dense_1/Softmaxhu  »B
ﬂ
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type) *Ä2 8Ä@ÄHÄbsequential/dense_1/Softmaxhu  »B
‰
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb;gradient_tape/sequential/conv2d/Conv2D/Conv2DBackpropFilterhuZUÖB
Ê
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb=gradient_tape/sequential/conv2d_3/Conv2D/Conv2DBackpropFilterhuZUÖB
F
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Å@ÅHÅbCasthu  »B
G
 Cast_GPU_DT_BOOL_DT_FLOAT_kernel*Ä28Ä@ÄHÄbCast_2hu  »B
z
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä@ÄHÄb8categorical_crossentropy/weighted_loss/num_elements/Casthu  »B
D
 Mul_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbMulhuZUÖB
ç
 Mul_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbLgradient_tape/categorical_crossentropy/softmax_cross_entropy_with_logits/mulhuZUÖB
‡
Évoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä28Ä@ÄHÄb;gradient_tape/categorical_crossentropy/weighted_loss/Tile_1huZUÖB
°
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb,categorical_crossentropy/weighted_loss/valuehuZUÖB
ˇ
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb
div_no_nanhuZUÖB
∫
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbEgradient_tape/categorical_crossentropy/weighted_loss/value/div_no_nanhuZUÖB
Í
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2 8Ä@ÄHÄb'gradient_tape/sequential/dense/ReluGradhuZUÖB
ò
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOphuZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_3huZUÖB
ò
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAdam/Adam/AssignAddVariableOphuZUÖB
ê
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_4huZUÖB
˜
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
è
Tvoid tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int)*Ä28Ä@ÄHÄbsequential/dense_1/BiasAddhuZUÖB
Î
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)0*Ä28Ä@ÄHÄbSum_2hu  »B
ê
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)0*Ä28Ä@ÄHÄb*categorical_crossentropy/weighted_loss/Sumhu  »B