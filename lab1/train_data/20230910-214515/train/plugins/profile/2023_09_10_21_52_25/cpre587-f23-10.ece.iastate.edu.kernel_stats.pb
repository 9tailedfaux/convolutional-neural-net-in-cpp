
ß
Ωvoid wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)`Ä*2Ä8è¯_@è¯_Hè¯_Xb@gradient_tape/sequential_3/conv2d_19/Conv2D/Conv2DBackpropFilterhu≥™&B
±
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_256x64_16x4_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_256x64_16x4_nhwc_unity_stride_align4::Params)ˇ ÄÄ*Ä2à8àË/@àË/HàË/Xb?gradient_tape/sequential_3/conv2d_19/Conv2D/Conv2DBackpropInputh
ß
Ωvoid wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)TÄ*2Ä8Ñ¯@Ñ¯HÑ¯Xb@gradient_tape/sequential_3/conv2d_18/Conv2D/Conv2DBackpropFilterhu≥™&B
è
 void fft2d_c2r_32x32<float, false, true, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)@ ¿ò*Ä2Ä8ÑË@Å®HÅÿbsequential_3/conv2d_19/ReluhuZUÖB
Z
ampere_gcgemm_64x64_ntzÄ¿*Ä2†8Éò@ÅÄHÅàbsequential_3/conv2d_19/ReluhuMUB
ß
Ωvoid wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)`Ä*2Ä8É∏@É∏HÉ∏Xb@gradient_tape/sequential_3/conv2d_20/Conv2D/Conv2DBackpropFilterhu≥™&B
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8É®@É®HÉ®b-gradient_tape/sequential_3/conv2d_18/ReluGradhuZUÖB
‰
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)@ ¿ò*Ä2Ä8ÉÄ@Å∏HÄ»bsequential_3/conv2d_19/ReluhuZUÖB
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Çò@ÇòHÇòb-gradient_tape/sequential_3/conv2d_19/ReluGradhuZUÖB
å
Hcudnn_infer_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1~ÄÄ*Ä2Ä8Ç∞@Ç∞HÇ∞bsequential_3/conv2d_21/ReluhuMUB
ÎS
ÖSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)| ÄÄ*Ä28Ç¯@Ç¯HÇ¯Xb@gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropFilterh
ú
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Äƒ*Ä2Ä 8É¿@É¿HÉ¿b>gradient_tape/sequential_3/max_pooling2d_9/MaxPool/MaxPoolGradhuZUÖB
Ñ
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2qÄ8ÇÄ@ÇÄHÇÄXb?gradient_tape/sequential_3/conv2d_19/Conv2D/Conv2DBackpropInputhu  »B
ë

≤	void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::MaxReducer<float, 0>, long>(Eigen::internal::MaxReducer<float, 0>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)0*Ä28Ç†@Ç†HÇ†b:categorical_crossentropy/softmax_cross_entropy_with_logitshu¶™¶B
w
4cudnn_infer_ampere_scudnn_128x32_relu_interior_nn_v1ÄÄ**@2ê8Çÿ@ÇÿHÇÿbsequential_3/conv2d_18/ReluhuMUB
y
4cudnn_infer_ampere_scudnn_128x64_relu_interior_nn_v1ÄÄÄ*Ä2§8Ç∏@Ç∏HÇ∏bsequential_3/conv2d_20/ReluhuMUB
Ñ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2bÄ8Ç∞@Ç∞HÇ∞Xb?gradient_tape/sequential_3/conv2d_19/Conv2D/Conv2DBackpropInputhu  »B
±
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params)° Ä¿*Ä2§8Å¯@Å¯HÅ¯Xb?gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropInputh
±
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params)° Ä¿*Ä2ê8Å–@Å–HÅ–Xb?gradient_tape/sequential_3/conv2d_20/Conv2D/Conv2DBackpropInputh
Ò
§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä*‡2Ä8Å–@Å–HÅ–b$sequential_3/max_pooling2d_9/MaxPoolhu  ØB
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Å¯@Å¯HÅ¯b-gradient_tape/sequential_3/conv2d_20/ReluGradhuZUÖB
Î
ãvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float) 0*Ä2Ä 8Å∞@Å∞HÅ∞b8gradient_tape/sequential_3/conv2d_18/BiasAdd/BiasAddGradhu  »B
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Å†@Å†HÅ†b-gradient_tape/sequential_3/conv2d_21/ReluGradhuZUÖB
Ç

£	void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, long>(Eigen::internal::SumReducer<float>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)(*Ä28Å–@Å–HÅ–b:categorical_crossentropy/softmax_cross_entropy_with_logitshu  »B
Î
ãvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float) 0*Ä2Ä 8Å∏@Å∏HÅ∏b8gradient_tape/sequential_3/conv2d_19/BiasAdd/BiasAddGradhu  »B
∂
◊void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, long>(Eigen::internal::SumReducer<float>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)(*Ä28Å†@Å†HÅ†b:categorical_crossentropy/softmax_cross_entropy_with_logitshu  »B
Ñ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Åà@ÅàHÅàXb?gradient_tape/sequential_3/conv2d_20/Conv2D/Conv2DBackpropInputhu  »B
Ñ
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Äà@ÄàHÄàXb?gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropInputhu  »B
Ö
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8ÅÄ@ÅÄHÅÄXb@gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropFilterhu  »B
ú
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä$*Ä2Ä@8Åÿ@ÅÿHÅÿb?gradient_tape/sequential_3/max_pooling2d_10/MaxPool/MaxPoolGradhu  »B
Ö
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Å®@Å®HÅ®Xb@gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropFilterhu  »B
Ñ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Å†@Å†HÅ†Xb?gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropInputhu  »B
ç
Hcudnn_infer_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile244t_nt_v1ÇÄÄ*Ä2Ä8ÄË@ÄËHÄËbsequential_3/conv2d_23/ReluhugUÖA
÷
ísm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel_cudnn_inferÚ ÄÄ*Ä2d8Å–@Å–HÅ–PXbsequential_3/conv2d_22/Reluh
Æ
»void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4::Params)v ÄÄ*Ä2»8Åà@ÅàHÅàXb?gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropInputh
Ú
§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä*ê2Ä8Å@ÅHÅb%sequential_3/max_pooling2d_10/MaxPoolhu ¿®B
Ñ
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8ÅË@ÅËHÅËXb?gradient_tape/sequential_3/conv2d_20/Conv2D/Conv2DBackpropInputhu  »B
˙S
ìSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 3, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 3, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)¶ Ä¿*Ä28Å‡@Å‡HÅ‡Xb@gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropFilterh
ù
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä*Ä2ÄÄ8Å–@Å–HÅ–b?gradient_tape/sequential_3/max_pooling2d_11/MaxPool/MaxPoolGradhu  »B
ÎS
ÖSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)| ÄÄ*Ä28Ä»@Ä»HÄ»Xb@gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropFilterh
Å
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*Ä2Ä8Ä»@Ä»HÄ»b8gradient_tape/sequential_3/conv2d_20/BiasAdd/BiasAddGradhu  »B
Æ
»void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4::Params)v ÄÄ*Ä2†8Ä¿@Ä¿HÄ¿Xb?gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropInputh
Å
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*Ä2Ä8Å†@Å†HÅ†b8gradient_tape/sequential_3/conv2d_21/BiasAdd/BiasAddGradhu  »B
π
™void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä`*Ä2Ä8Ä@ÄHÄbfgradient_tape/sequential_3/conv2d_18/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizerhuZUÖB
ˇ
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2T8Ä‡@Ä‡HÄ‡b%Adam/Adam/update_12/ResourceApplyAdamhuZUÖB
Ö
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Åò@ÅòHÅòXb@gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropFilterhu  »B
Ö
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äà@ÄàHÄàXb@gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropFilterhu  »B
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8ÄÄ@ÄÄHÄÄb-gradient_tape/sequential_3/conv2d_23/ReluGradhuZUÖB

°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Äx@ÄxHÄxb-gradient_tape/sequential_3/conv2d_22/ReluGradhuZUÖB
¬
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4::Params)d ÄÄ*Ä28Äx@ÄxHÄxXbsequential_3/dense_6/MatMulh
Ç
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äp@ÄpHÄpXb@gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropFilterhu  »B
€
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äp@ÄpHÄpbsequential_3/conv2d_22/Reluhu  »B
ﬂ
ûvoid fft2d_r2c_32x32<float, false, 5u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)@ ¿ò*Ä2@8Äp@ÄpHÄpbsequential_3/conv2d_19/ReluhuZUÖB
Ç
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äh@ÄhHÄhXb@gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropFilterhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Äh@ÄhHÄhXb?gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropInputhu  »B
π
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)Ä*Ä2Ä8Äh@ÄhHÄhb8gradient_tape/sequential_3/conv2d_23/BiasAdd/BiasAddGradhuZUÖB
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä`@Ä`HÄ`Xb?gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropInputhu  »B
µ
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long) *Ä28ÅP@ÅPHÅPbArgMax_1huZUÖB
≥
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long) *Ä28ÄP@ÄPHÄPbArgMaxhuZUÖB
”
Üvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4>(cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4::Params)î Ä¿*Ä2@8ÄH@ÄHHÄHb+gradient_tape/sequential_3/dense_6/MatMul_1h
“
Üvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x10_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x10_tn_align4::Params)X ÄÄ*Ä28ÄH@ÄHHÄHXb)gradient_tape/sequential_3/dense_6/MatMulh
π
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)Ä*Ä2Ä8Ä@@Ä@HÄ@b8gradient_tape/sequential_3/conv2d_22/BiasAdd/BiasAddGradhuZUÖB
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä8@Ä8HÄ8Xb?gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropInputhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Ä8@Ä8HÄ8Xb?gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropInputhu  »B
’
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align4::Params)Z ÄÄ*Ä28Ä8@Ä8HÄ8Xb)gradient_tape/sequential_3/dense_7/MatMulhugUÖA
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2H8Ä8@Ä8HÄ8b%Adam/Adam/update_10/ResourceApplyAdamhuZUÖB
≥
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä!*Ä2Ä8Ä8@Ä8HÄ8begradient_tape/sequential_3/max_pooling2d_11/MaxPool/MaxPoolGrad-2-TransposeNHWCToNCHW-LayoutOptimizerhu  »B
Ó
§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä * 2Ä8Ä0@Ä0HÄ0b%sequential_3/max_pooling2d_11/MaxPoolhu  »B
«
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params)^ ÄÄ*Ä28Ä0@Ä0HÄ0Xbsequential_3/dense_7/MatMulhugUÖA
’
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nt_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_nt_align4::Params)\ ÄÄ*Ä28Ä0@Ä0HÄ0b+gradient_tape/sequential_3/dense_7/MatMul_1hugUÖA
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2$8Ä0@Ä0HÄ0b$Adam/Adam/update_6/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2$8Ä0@Ä0HÄ0b$Adam/Adam/update_8/ResourceApplyAdamhuZUÖB
õ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä!*Ä2Ä8Å(@Å(HÅ(bMsequential_3/max_pooling2d_11/MaxPool-0-2-TransposeNCHWToNHWC-LayoutOptimizerhu  »B
≈
Èvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_quotient_op<float, float>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_quotient_op<float, float>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long).*Ä28Ä(@Ä(HÄ(b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
∆
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 28Ä(@Ä(HÄ(Xb@gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropFilterhu  »B
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä(@Ä(HÄ(b$Adam/Adam/update_4/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä(@Ä(HÄ(b$Adam/Adam/update_2/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä228Ä(@Ä(HÄ(b%Adam/Adam/update_14/ResourceApplyAdamhuZUÖB
_
!Cast_GPU_DT_INT64_DT_FLOAT_kernel*Ä2d8Ä @Ä HÄ bcategorical_crossentropy/Casthu  »B
ˇ	
£	void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)&*Ä28Ä @Ä HÄ b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
≠
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long)(*Ä28Ä @Ä HÄ b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2 8Ä @Ä HÄ Xb?gradient_tape/sequential_3/conv2d_19/Conv2D/Conv2DBackpropInputhu  »B
⁄
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä @Ä HÄ bsequential_3/conv2d_22/Reluhu  »B
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä @Ä HÄ Xb?gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropInputhu  »B
Ç
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Ä @Ä HÄ Xb@gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropFilterhu  »B
º
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)(ÄD* 28Ä @Ä HÄ bsequential_3/conv2d_21/ReluhuZU∑B
∆
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 2 8Ä @Ä HÄ Xb@gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropFilterhu  »B
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_1/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b%Adam/Adam/update_11/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b%Adam/Adam/update_13/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_3/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_5/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_7/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_9/ResourceApplyAdamhuZUÖB
˘
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b"Adam/Adam/update/ResourceApplyAdamhuZUÖB
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä @Ä HÄ b8gradient_tape/sequential_3/conv2d_21/BiasAdd/BiasAddGradhuZUÖB
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ bsequential_3/conv2d_18/ReluhuZUÖB
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ bsequential_3/conv2d_20/ReluhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb@gradient_tape/sequential_3/conv2d_20/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb?gradient_tape/sequential_3/conv2d_20/Conv2D/Conv2DBackpropInputhuZUÖB
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ bsequential_3/conv2d_19/ReluhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb@gradient_tape/sequential_3/conv2d_19/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb?gradient_tape/sequential_3/conv2d_19/Conv2D/Conv2DBackpropInputhuZUÖB
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ bsequential_3/conv2d_22/ReluhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb@gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb?gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropInputhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb@gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb?gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropInputhuZUÖB
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ bsequential_3/conv2d_23/ReluhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ Xb?gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropInputhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Å@ÅHÅb%Adam/Adam/update_15/ResourceApplyAdamhuZUÖB
K
"AddV2_GPU_DT_INT64_DT_INT64_kernel*Ä28Ä@ÄHÄbAdam/addhuZUÖB
G
 Cast_GPU_DT_BOOL_DT_FLOAT_kernel*Ä28Ä@ÄHÄbCast_2hu  »B
I
 Pow_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbAdam/PowhuZUÖB
K
 Pow_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄb
Adam/Pow_1huZUÖB
‡
Évoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä28Ä@ÄHÄb;gradient_tape/categorical_crossentropy/weighted_loss/Tile_1huZUÖB
Å
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbdiv_no_nan_1huZUÖB
∫
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbEgradient_tape/categorical_crossentropy/weighted_loss/value/div_no_nanhuZUÖB
⁄
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2 8Ä@ÄHÄbsequential_3/dense_6/ReluhuZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_1huZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_2huZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_3huZUÖB
ò
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAdam/Adam/AssignAddVariableOphuZUÖB
ê
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_4huZUÖB
˜
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
ù
avoid cask_cudnn_infer::computeOffsetsKernel<false, false>(cask_cudnn_infer::ComputeOffsetsParams)*Ä28Ä@ÄHÄbsequential_3/conv2d_20/Reluhu  »B
ù
avoid cask_cudnn_infer::computeOffsetsKernel<false, false>(cask_cudnn_infer::ComputeOffsetsParams)*Ä28Ä@ÄHÄbsequential_3/conv2d_18/Reluhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb?gradient_tape/sequential_3/conv2d_20/Conv2D/Conv2DBackpropInputhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb?gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropInputhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb?gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropInputhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä@ÄHÄXb@gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropFilterhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä@ÄHÄXb@gradient_tape/sequential_3/conv2d_22/Conv2D/Conv2DBackpropFilterhu  »B
º
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)(ÄD* 28Ä@ÄHÄbsequential_3/conv2d_23/ReluhuZU∑B
∆
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 28Ä@ÄHÄXb@gradient_tape/sequential_3/conv2d_21/Conv2D/Conv2DBackpropFilterhu  »B
›
ùvoid splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*) *Ä2»8Ä@ÄHÄXbsequential_3/dense_7/MatMulhu  »B
›
ùvoid splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*) *Ä2Ä8Ä@ÄHÄXbsequential_3/dense_6/MatMulhu  »B
œ
ëvoid tensorflow::(anonymous namespace)::GenerateNormalizedProb<float, float, 4>(float const*, float const*, float const*, float*, int, int, bool) *Ä228Ä@ÄHÄbsequential_3/dense_7/Softmaxhu  »B
¨
Rvoid tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int) †*Ä28Ä@ÄHÄb6gradient_tape/sequential_3/dense_7/BiasAdd/BiasAddGradhuZUÖB
ë
Tvoid tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int)*Ä28Ä@ÄHÄbsequential_3/dense_7/BiasAddhuZUÖB
ë
Tvoid tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int)*Ä2 8Ä@ÄHÄbsequential_3/dense_6/BiasAddhuZUÖB
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb8gradient_tape/sequential_3/conv2d_18/BiasAdd/BiasAddGradhuZUÖB
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb8gradient_tape/sequential_3/conv2d_20/BiasAdd/BiasAddGradhuZUÖB
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb8gradient_tape/sequential_3/conv2d_21/BiasAdd/BiasAddGradhuZUÖB
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb8gradient_tape/sequential_3/conv2d_18/BiasAdd/BiasAddGradhuZUÖB
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb8gradient_tape/sequential_3/conv2d_19/BiasAdd/BiasAddGradhuZUÖB
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb8gradient_tape/sequential_3/conv2d_20/BiasAdd/BiasAddGradhuZUÖB
É
≈void tensorflow::functor::RowReduceKernel<cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, cub::Sum>(cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, int, int, cub::Sum, std::iterator_traits<cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long> >::value_type)*Ä2 8Ä@ÄHÄbsequential_3/dense_7/Softmaxhu  »B
·
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type) *Ä2 8Ä@ÄHÄbsequential_3/dense_7/Softmaxhu  »B
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb@gradient_tape/sequential_3/conv2d_18/Conv2D/Conv2DBackpropFilterhuZUÖB
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄbsequential_3/conv2d_21/ReluhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä@ÄHÄXb@gradient_tape/sequential_3/conv2d_23/Conv2D/Conv2DBackpropFilterhuZUÖB
F
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä@ÄHÄbCasthu  »B
H
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä@ÄHÄbCast_3hu  »B
z
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä@ÄHÄb8categorical_crossentropy/weighted_loss/num_elements/Casthu  »B
M
!Cast_GPU_DT_INT64_DT_FLOAT_kernel*Ä28Ä@ÄHÄbAdam/Cast_1hu  »B
G
!Equal_GPU_DT_INT64_DT_BOOL_kernel*Ä28Ä@ÄHÄbEqualhuZUÖB
P
%LogicalAnd_GPU_DT_BOOL_DT_BOOL_kernel*Ä28Ä@ÄHÄb
LogicalAndhuZUÖB
D
 Mul_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbMulhuZUÖB
ç
 Mul_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbLgradient_tape/categorical_crossentropy/softmax_cross_entropy_with_logits/mulhuZUÖB
°
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb,categorical_crossentropy/weighted_loss/valuehuZUÖB
ˇ
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb
div_no_nanhuZUÖB
Ó
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2 8Ä@ÄHÄb+gradient_tape/sequential_3/dense_6/ReluGradhuZUÖB
ò
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOphuZUÖB
¨
Rvoid tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int) Ä*Ä2 8Ä@ÄHÄb6gradient_tape/sequential_3/dense_6/BiasAdd/BiasAddGradhuZUÖB
Î
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)0*Ä28Ä@ÄHÄbSum_2hu  »B
ê
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)0*Ä28Ä@ÄHÄb*categorical_crossentropy/weighted_loss/Sumhu  »B
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb8gradient_tape/sequential_3/conv2d_19/BiasAdd/BiasAddGradhuZUÖB