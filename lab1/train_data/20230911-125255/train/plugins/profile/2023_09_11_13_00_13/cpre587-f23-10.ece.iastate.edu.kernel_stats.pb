
ß
Ωvoid wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)`Ä*2Ä8í‡_@í‡_Hí‡_Xb@gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropFilterhu≥™&B
±
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_256x64_16x4_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_256x64_16x4_nhwc_unity_stride_align4::Params)ˇ ÄÄ*Ä2à8â‡/@â‡/Hâ‡/Xb?gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropInputh
ß
Ωvoid wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)TÄ*2Ä8Ñ»@Ñ»HÑ»Xb@gradient_tape/sequential_2/conv2d_12/Conv2D/Conv2DBackpropFilterhu≥™&B
è
 void fft2d_c2r_32x32<float, false, true, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)@ ¿ò*Ä2Ä8Ñ»@Å®HÅ∏bsequential_2/conv2d_13/ReluhuZUÖB
Z
ampere_gcgemm_64x64_ntzÄ¿*Ä2†8Ñ†@ÅÄHÅêbsequential_2/conv2d_13/ReluhuMUB
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Ñ†@Ñ†HÑ†b-gradient_tape/sequential_2/conv2d_12/ReluGradhuZUÖB
ß
Ωvoid wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)`Ä*2Ä8ÑË@ÑËHÑËXb@gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropFilterhu≥™&B
‰
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)@ ¿ò*Ä2Ä8ÑÄ@Å∏HÅ»bsequential_2/conv2d_13/ReluhuZUÖB
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8É†@É†HÉ†b-gradient_tape/sequential_2/conv2d_13/ReluGradhuZUÖB
å
Hcudnn_infer_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1~ÄÄ*Ä2Ä8É®@É®HÉ®bsequential_2/conv2d_15/ReluhuMUB
ÎS
ÖSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)| ÄÄ*Ä28ÉÄ@ÉÄHÉÄXb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterh
ú
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Äƒ*Ä2Ä 8Ç¿@Ç¿HÇ¿b>gradient_tape/sequential_2/max_pooling2d_6/MaxPool/MaxPoolGradhuZUÖB
Ñ
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2qÄ8ÇÄ@ÇÄHÇÄXb?gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropInputhu  »B
ë

≤	void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::MaxReducer<float, 0>, long>(Eigen::internal::MaxReducer<float, 0>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float, 0>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)0*Ä28É†@É†HÉ†b:categorical_crossentropy/softmax_cross_entropy_with_logitshu¶™¶B
w
4cudnn_infer_ampere_scudnn_128x32_relu_interior_nn_v1ÄÄ**@2ê8Ç–@Ç–HÇ–bsequential_2/conv2d_12/ReluhuMUB
y
4cudnn_infer_ampere_scudnn_128x64_relu_interior_nn_v1ÄÄÄ*Ä2§8Ç∞@Ç∞HÇ∞bsequential_2/conv2d_14/ReluhuMUB
Ñ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2bÄ8Ç®@Ç®HÇ®Xb?gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropInputhu  »B
±
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params)° Ä¿*Ä2§8Åà	@Åà	HÅà	Xb?gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropInputh
±
 void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params)° Ä¿*Ä2ê8Ç‡@Ç‡HÇ‡Xb?gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropInputh
Ò
§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä*‡2Ä8Å–@Å–HÅ–b$sequential_2/max_pooling2d_6/MaxPoolhu  ØB
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Å¯@Å¯HÅ¯b-gradient_tape/sequential_2/conv2d_14/ReluGradhuZUÖB
Î
ãvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float) 0*Ä2Ä 8Ç®@Ç®HÇ®b8gradient_tape/sequential_2/conv2d_12/BiasAdd/BiasAddGradhu  »B
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8Ç†@Ç†HÇ†b-gradient_tape/sequential_2/conv2d_15/ReluGradhuZUÖB
Ç

£	void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, long>(Eigen::internal::SumReducer<float>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)(*Ä28Å»@Å»HÅ»b:categorical_crossentropy/softmax_cross_entropy_with_logitshu  »B
Î
ãvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float) 0*Ä2Ä 8Å∏@Å∏HÅ∏b8gradient_tape/sequential_2/conv2d_13/BiasAdd/BiasAddGradhu  »B
∂
◊void Eigen::internal::InnerReductionKernel<128, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, long>(Eigen::internal::SumReducer<float>, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long, long, Eigen::TensorReductionEvaluatorBase<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<1l>> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>::CoeffReturnType*)(*Ä28Åò@ÅòHÅòb:categorical_crossentropy/softmax_cross_entropy_with_logitshu  »B
Ñ
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Åê@ÅêHÅêXb?gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropInputhu  »B
Ñ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Åà@ÅàHÅàXb?gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropInputhu  »B
Ö
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Åà@ÅàHÅàXb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
õ
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä$*Ä2Ä@8Å‡@Å‡HÅ‡b>gradient_tape/sequential_2/max_pooling2d_7/MaxPool/MaxPoolGradhu  »B
Ö
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Å®@Å®HÅ®Xb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
Ñ
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä†@Ä†HÄ†Xb?gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropInputhu  »B
ç
Hcudnn_infer_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile244t_nt_v1ÇÄÄ*Ä2Ä8Å‡@Å‡HÅ‡bsequential_2/conv2d_17/ReluhugUÖA
÷
ísm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel_cudnn_inferÚ ÄÄ*Ä2d8Å–@Å–HÅ–PXbsequential_2/conv2d_16/Reluh
Æ
»void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4::Params)v ÄÄ*Ä2»8Åê@ÅêHÅêXb?gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropInputh
Ñ
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Ä¯@Ä¯HÄ¯Xb?gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropInputhu  »B
Ò
§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä*ê2Ä8Å@ÅHÅb$sequential_2/max_pooling2d_7/MaxPoolhu ¿®B
˙S
ìSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 3, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<32, 128>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<128, 32>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 3, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 128, 32>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 64, 32>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)¶ Ä¿*Ä28Å‡@Å‡HÅ‡Xb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterh
ú
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor) Ä*Ä2ÄÄ8Å»@Å»HÅ»b>gradient_tape/sequential_2/max_pooling2d_8/MaxPool/MaxPoolGradhu  »B
Å
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*Ä2Ä8Ä»@Ä»HÄ»b8gradient_tape/sequential_2/conv2d_14/BiasAdd/BiasAddGradhu  »B
ÎS
ÖSvoid cutlass_cudnn_train::Kernel<cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0> >(cutlass_cudnn_train::conv::kernel::ImplicitGemmConvolution<cutlass_cudnn_train::conv::threadblock::ImplicitGemmMultistage<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<64, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::conv::threadblock::Conv2dWgradActivationTileAccessIteratorOptimized<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, cutlass_cudnn_train::AlignedArray<cutlass_cudnn_train::tfloat32_t, 4, 16> >, cutlass_cudnn_train::transform::threadblock::RegularTileAccessIterator<cutlass_cudnn_train::MatrixShape<16, 64>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass_cudnn_train::transform::PitchLinearWarpRakedThreadMap<cutlass_cudnn_train::PitchLinearShape<64, 16>, 128, cutlass_cudnn_train::PitchLinearShape<8, 4>, 4>, 16>, (cutlass_cudnn_train::arch::CacheOperation::Kind)0, cutlass_cudnn_train::gemm::threadblock::MmaPolicy<cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, cutlass_cudnn_train::MatrixShape<0, 0>, cutlass_cudnn_train::MatrixShape<0, 0>, 1>, 10, bool>, cutlass_cudnn_train::epilogue::threadblock::Epilogue<cutlass_cudnn_train::gemm::GemmShape<64, 64, 16>, cutlass_cudnn_train::gemm::warp::MmaTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::gemm::warp::MmaTensorOpPolicy<cutlass_cudnn_train::arch::Mma<cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, 32, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::tfloat32_t, cutlass_cudnn_train::layout::ColumnMajor, float, cutlass_cudnn_train::layout::RowMajor, cutlass_cudnn_train::arch::OpMultiplyAdd>, cutlass_cudnn_train::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass_cudnn_train::epilogue::threadblock::PredicatedTileIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float, false, cutlass_cudnn_train::layout::NoPermute, false>, cutlass_cudnn_train::epilogue::warp::FragmentIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::Array<float, 4, true>, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::warp::TileIteratorTensorOp<cutlass_cudnn_train::gemm::GemmShape<32, 32, 16>, cutlass_cudnn_train::gemm::GemmShape<16, 8, 8>, float, cutlass_cudnn_train::layout::RowMajor>, cutlass_cudnn_train::epilogue::threadblock::SharedLoadIterator<cutlass_cudnn_train::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass_cudnn_train::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::MatrixShape<0, 8>, 2, 1>, cutlass_cudnn_train::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass_cudnn_train::conv::Operator)2, cutlass_cudnn_train::conv::Conv2dProblemSize, (cutlass_cudnn_train::conv::GroupMode)0>::Params)| ÄÄ*Ä28Å¿@Å¿HÅ¿Xb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterh
Æ
»void cutlass_cudnn_infer::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4::Params)v ÄÄ*Ä2†8Ä¿@Ä¿HÄ¿Xb?gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropInputh
Å
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*Ä2Ä8Ä†@Ä†HÄ†b8gradient_tape/sequential_2/conv2d_15/BiasAdd/BiasAddGradhu  »B
π
™void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä`*Ä2Ä8Å@ÅHÅbfgradient_tape/sequential_2/conv2d_12/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizerhuZUÖB
ˇ
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2T8Åÿ@ÅÿHÅÿb%Adam/Adam/update_12/ResourceApplyAdamhuZUÖB
Ö
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äê@ÄêHÄêXb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
Ö
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äà@ÄàHÄàXb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterhu  »B
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8ÄÄ@ÄÄHÄÄb-gradient_tape/sequential_2/conv2d_16/ReluGradhuZUÖB
Û
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2~8ÄÄ@ÄÄHÄÄb-gradient_tape/sequential_2/conv2d_17/ReluGradhuZUÖB
¬
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4::Params)d ÄÄ*Ä28Äx@ÄxHÄxXbsequential_2/dense_4/MatMulh
Ç
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äp@ÄpHÄpXb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterhu  »B
€
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äp@ÄpHÄpbsequential_2/conv2d_16/Reluhu  »B
ﬂ
ûvoid fft2d_r2c_32x32<float, false, 5u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)@ ¿ò*Ä2@8Äp@ÄpHÄpbsequential_2/conv2d_13/ReluhuZUÖB
π
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)Ä*Ä2Ä8Äp@ÄpHÄpb8gradient_tape/sequential_2/conv2d_17/BiasAdd/BiasAddGradhuZUÖB
Ç
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Äh@ÄhHÄhXb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Å`@Å`HÅ`Xb?gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropInputhu  »B
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä`@Ä`HÄ`Xb?gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropInputhu  »B
≥
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long) *Ä28ÄX@ÄXHÄXbArgMaxhuZUÖB
µ
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorTupleReducerOp<Eigen::internal::ArgMaxTupleReducer<Eigen::Tuple<long, float> >, Eigen::array<long, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long) *Ä28ÄP@ÄPHÄPbArgMax_1huZUÖB
”
Üvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4>(cutlass_80_tensorop_s1688gemm_128x64_16x6_nt_align4::Params)î Ä¿*Ä2@8ÅH@ÅHHÅHb+gradient_tape/sequential_2/dense_4/MatMul_1h
“
Üvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x10_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x10_tn_align4::Params)X ÄÄ*Ä28ÄH@ÄHHÄHXb)gradient_tape/sequential_2/dense_4/MatMulh
π
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)Ä*Ä2Ä8Ä@@Ä@HÄ@b8gradient_tape/sequential_2/conv2d_16/BiasAdd/BiasAddGradhuZUÖB
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä8@Ä8HÄ8Xb?gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropInputhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Ä8@Ä8HÄ8Xb?gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropInputhu  »B
Ì
§void cudnn::ops::pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)( Ä * 2Ä8Ä8@Ä8HÄ8b$sequential_2/max_pooling2d_8/MaxPoolhu  »B
’
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align4::Params)Z ÄÄ*Ä28Ä8@Ä8HÄ8Xb)gradient_tape/sequential_2/dense_5/MatMulhugUÖA
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2H8Ä8@Ä8HÄ8b%Adam/Adam/update_10/ResourceApplyAdamhuZUÖB
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä!*Ä2Ä8Ä8@Ä8HÄ8bdgradient_tape/sequential_2/max_pooling2d_8/MaxPool/MaxPoolGrad-2-TransposeNHWCToNCHW-LayoutOptimizerhu  »B
«
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params)^ ÄÄ*Ä28Ä0@Ä0HÄ0Xbsequential_2/dense_5/MatMulhugUÖA
’
Ñvoid cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nt_align4>(cutlass_80_tensorop_s1688gemm_64x64_16x6_nt_align4::Params)\ ÄÄ*Ä28Ä0@Ä0HÄ0b+gradient_tape/sequential_2/dense_5/MatMul_1hugUÖA
≈
Èvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_quotient_op<float, float>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_quotient_op<float, float>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long).*Ä28Ä(@Ä(HÄ(b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
∆
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 28Ä(@Ä(HÄ(Xb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
˘
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä(@Ä(HÄ(b"Adam/Adam/update/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä(@Ä(HÄ(b$Adam/Adam/update_4/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä(@Ä(HÄ(b$Adam/Adam/update_2/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2$8Ä(@Ä(HÄ(b$Adam/Adam/update_6/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä2$8Ä(@Ä(HÄ(b$Adam/Adam/update_8/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä228Ä(@Ä(HÄ(b%Adam/Adam/update_14/ResourceApplyAdamhuZUÖB
ö
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*) Ä!*Ä2Ä8Ä(@Ä(HÄ(bLsequential_2/max_pooling2d_8/MaxPool-0-2-TransposeNCHWToNHWC-LayoutOptimizerhu  »B
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Å @Å HÅ Xb?gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropInputhuZUÖB
≠
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorForcedEvalOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long)(*Ä28Ä @Ä HÄ b:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
⁄
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä @Ä HÄ bsequential_2/conv2d_16/Reluhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä @Ä HÄ Xb?gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropInputhu  »B
Ç
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2Ä8Ä @Ä HÄ Xb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterhu  »B
∆
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 2 8Ä @Ä HÄ Xb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterhu  »B
›
ùvoid splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*) *Ä2Ä8Ä @Ä HÄ Xbsequential_2/dense_4/MatMulhu  »B
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b%Adam/Adam/update_11/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b%Adam/Adam/update_13/ResourceApplyAdamhuZUÖB
¸
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b%Adam/Adam/update_15/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_3/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_5/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_7/ResourceApplyAdamhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä @Ä HÄ b$Adam/Adam/update_9/ResourceApplyAdamhuZUÖB
É
≈void tensorflow::functor::RowReduceKernel<cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, cub::Sum>(cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long>, float*, int, int, cub::Sum, std::iterator_traits<cub::TransformInputIterator<float, tensorflow::(anonymous namespace)::SubtractAndExpFunctor<float, float>, cub::CountingInputIterator<int, long>, long> >::value_type)*Ä2 8Ä @Ä HÄ bsequential_2/dense_5/Softmaxhu  »B
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ bsequential_2/conv2d_14/ReluhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb@gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropFilterhuZUÖB
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ bsequential_2/conv2d_13/ReluhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä @Ä HÄ Xb?gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropInputhuZUÖB
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ bsequential_2/conv2d_16/ReluhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb?gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropInputhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä @Ä HÄ Xb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterhuZUÖB
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ bsequential_2/conv2d_17/ReluhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ Xb@gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2H8Ä @Ä HÄ Xb?gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropInputhuZUÖB
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Å@ÅHÅb8gradient_tape/sequential_2/conv2d_14/BiasAdd/BiasAddGradhuZUÖB
K
"AddV2_GPU_DT_INT64_DT_INT64_kernel*Ä28Ä@ÄHÄbAdam/addhuZUÖB
F
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä@ÄHÄbCasthu  »B
z
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä@ÄHÄb8categorical_crossentropy/weighted_loss/num_elements/Casthu  »B
M
!Cast_GPU_DT_INT64_DT_FLOAT_kernel*Ä28Ä@ÄHÄbAdam/Cast_1hu  »B
_
!Cast_GPU_DT_INT64_DT_FLOAT_kernel*Ä2d8Ä@ÄHÄbcategorical_crossentropy/Casthu  »B
D
 Mul_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbMulhuZUÖB
I
 Pow_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbAdam/PowhuZUÖB
K
 Pow_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄb
Adam/Pow_1huZUÖB
‡
Évoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*Ä28Ä@ÄHÄb;gradient_tape/categorical_crossentropy/weighted_loss/Tile_1huZUÖB
°
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb,categorical_crossentropy/weighted_loss/valuehuZUÖB
Å
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbdiv_no_nan_1huZUÖB
⁄
üvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const, 1>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*Ä2 8Ä@ÄHÄbsequential_2/dense_4/ReluhuZUÖB
ò
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOphuZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_3huZUÖB
ˇ	
£	void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const, float const>, Eigen::TensorBroadcastingOp<Eigen::array<long, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<1l>, int> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)&*Ä28Ä@ÄHÄb:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
ò
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAdam/Adam/AssignAddVariableOphuZUÖB
ê
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long const, long const>, Eigen::TensorMap<Eigen::Tensor<long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_4huZUÖB
˜
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorEvalToOp<Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_log_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::MakePointer> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb:categorical_crossentropy/softmax_cross_entropy_with_logitshuZUÖB
ù
avoid cask_cudnn_infer::computeOffsetsKernel<false, false>(cask_cudnn_infer::ComputeOffsetsParams)*Ä28Ä@ÄHÄbsequential_2/conv2d_14/Reluhu  »B
ù
avoid cask_cudnn_infer::computeOffsetsKernel<false, false>(cask_cudnn_infer::ComputeOffsetsParams)*Ä28Ä@ÄHÄbsequential_2/conv2d_12/Reluhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2 8Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropInputhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropInputhu  »B
Ä
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2@8Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropInputhu  »B
Å
övoid cudnn::ops::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::ops::nchw2nhwc_params_t<float>, float const*, float*)!Ä!*Ä2Ä8Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_17/Conv2D/Conv2DBackpropInputhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
Å
övoid cudnn::ops::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<float>, float const*, float*)(Ä!*Ä2@8Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_16/Conv2D/Conv2DBackpropFilterhu  »B
º
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)(ÄD* 28Ä@ÄHÄbsequential_2/conv2d_15/ReluhuZU∑B
º
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)(ÄD* 28Ä@ÄHÄbsequential_2/conv2d_17/ReluhuZU∑B
∆
„void cutlass_cudnn_train::Kernel<cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass_cudnn_train::reduction::kernel::ReduceSplitK<cutlass_cudnn_train::MatrixShape<4, 128>, cutlass_cudnn_train::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass_cudnn_train::epilogue::thread::ScaleType::Kind)0, (cutlass_cudnn_train::FloatRoundStyle)2>, cutlass_cudnn_train::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)$* 28Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterhu  »B
›
ùvoid splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*) *Ä2»8Ä@ÄHÄXbsequential_2/dense_5/MatMulhu  »B
œ
ëvoid tensorflow::(anonymous namespace)::GenerateNormalizedProb<float, float, 4>(float const*, float const*, float const*, float*, int, int, bool) *Ä228Ä@ÄHÄbsequential_2/dense_5/Softmaxhu  »B
¨
Rvoid tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int) Ä*Ä2 8Ä@ÄHÄb6gradient_tape/sequential_2/dense_4/BiasAdd/BiasAddGradhuZUÖB
ë
Tvoid tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int)*Ä28Ä@ÄHÄbsequential_2/dense_5/BiasAddhuZUÖB
ë
Tvoid tensorflow::BiasNHWCKernel<float>(int, float const*, float const*, float*, int)*Ä2 8Ä@ÄHÄbsequential_2/dense_4/BiasAddhuZUÖB
˚
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool) *Ä28Ä@ÄHÄb$Adam/Adam/update_1/ResourceApplyAdamhuZUÖB
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_12/BiasAdd/BiasAddGradhuZUÖB
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_13/BiasAdd/BiasAddGradhuZUÖB
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_12/BiasAdd/BiasAddGradhuZUÖB
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_13/BiasAdd/BiasAddGradhuZUÖB
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_14/BiasAdd/BiasAddGradhuZUÖB
Ç
¶void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)Ä!*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_15/BiasAdd/BiasAddGradhuZUÖB
·
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Max>(float const*, float*, int, int, cub::Max, std::iterator_traits<float const*>::value_type) *Ä2 8Ä@ÄHÄbsequential_2/dense_5/Softmaxhu  »B
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄbsequential_2/conv2d_12/ReluhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_12/Conv2D/Conv2DBackpropFilterhuZUÖB
Ë
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb?gradient_tape/sequential_2/conv2d_14/Conv2D/Conv2DBackpropInputhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä28Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_13/Conv2D/Conv2DBackpropFilterhuZUÖB
¬
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄbsequential_2/conv2d_15/ReluhuZUÖB
È
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*Ä2$8Ä@ÄHÄXb@gradient_tape/sequential_2/conv2d_15/Conv2D/Conv2DBackpropFilterhuZUÖB
G
 Cast_GPU_DT_BOOL_DT_FLOAT_kernel*Ä28Ä@ÄHÄbCast_2hu  »B
H
!Cast_GPU_DT_INT32_DT_FLOAT_kernel*Ä28Ä@ÄHÄbCast_3hu  »B
G
!Equal_GPU_DT_INT64_DT_BOOL_kernel*Ä28Ä@ÄHÄbEqualhuZUÖB
P
%LogicalAnd_GPU_DT_BOOL_DT_BOOL_kernel*Ä28Ä@ÄHÄb
LogicalAndhuZUÖB
ç
 Mul_GPU_DT_FLOAT_DT_FLOAT_kernel*Ä28Ä@ÄHÄbLgradient_tape/categorical_crossentropy/softmax_cross_entropy_with_logits/mulhuZUÖB
ˇ
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄb
div_no_nanhuZUÖB
∫
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbEgradient_tape/categorical_crossentropy/weighted_loss/value/div_no_nanhuZUÖB
Ó
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const> const> const, Eigen::GpuDevice>, long)*Ä2 8Ä@ÄHÄb+gradient_tape/sequential_2/dense_4/ReluGradhuZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_1huZUÖB
ö
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*Ä28Ä@ÄHÄbAssignAddVariableOp_2huZUÖB
¨
Rvoid tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const*, float*, int) †*Ä28Ä@ÄHÄb6gradient_tape/sequential_2/dense_5/BiasAdd/BiasAddGradhuZUÖB
Î
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)0*Ä28Ä@ÄHÄbSum_2hu  »B
ê
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)0*Ä28Ä@ÄHÄb*categorical_crossentropy/weighted_loss/Sumhu  »B
Ô
ñvoid tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<float*>::value_type)*  28Ä@ÄHÄb8gradient_tape/sequential_2/conv2d_15/BiasAdd/BiasAddGradhuZUÖB